{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        # Initialize weights (to be set later based on input dimensions)\n",
    "        self.w = None\n",
    "        # Learning rate\n",
    "        self.alpha = 1\n",
    "\n",
    "    # Set the learning rate\n",
    "    def set_learning_rate(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # Fit the model to the data\n",
    "    def fit(self, X, y, iterations=1500):\n",
    "        self.y = y\n",
    "        # Add a bias term (column of ones) to X\n",
    "        self.X = np.c_[X, np.ones(X.shape[0])]\n",
    "        # Initialize weights (one for each feature + 1 for the bias)\n",
    "        self.w = np.zeros(self.X.shape[1])\n",
    "\n",
    "        # Gradient descent iterations\n",
    "        for i in range(iterations):\n",
    "            self.make_one_update()\n",
    "\n",
    "    # Perform one update step using gradient descent\n",
    "    def make_one_update(self):\n",
    "        w_current = self.w\n",
    "        # Compute the gradient\n",
    "        step = -self.alpha * self.compute_gradient(w_current)\n",
    "        # Update weights\n",
    "        self.w += step\n",
    "\n",
    "        # Report loss progression\n",
    "        current_loss = self.sq_loss(w_current)\n",
    "        update_loss = self.sq_loss(self.w)\n",
    "        if current_loss > update_loss:\n",
    "            print(f\"Loss decreases to {update_loss}\")\n",
    "        else:\n",
    "            print(f\"Loss increases to {update_loss}\")\n",
    "\n",
    "    # Compute the gradient\n",
    "    def compute_gradient(self, w_current):\n",
    "        # Gradient vector calculation\n",
    "        gradient = 2 * np.dot(self.X.T, (np.dot(self.X, w_current) - self.y))\n",
    "        print(f\"The norm of gradient vector is {np.linalg.norm(gradient)}\")\n",
    "        return gradient\n",
    "\n",
    "    # Compute the square loss\n",
    "    def sq_loss(self, w):\n",
    "        # Loss calculation\n",
    "        loss = np.sum(np.square(np.dot(self.X, w) - self.y))\n",
    "        return loss\n",
    "\n",
    "    # Predict new values\n",
    "    def predict(self, X):\n",
    "        # Add bias term to input features\n",
    "        X = np.c_[X, np.ones(X.shape[0])]\n",
    "        return np.dot(X, self.w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data, columns=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]].values\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The norm of gradient vector is 9750146.653150516\n",
      "Loss increases to 470522.0777566256\n",
      "The norm of gradient vector is 14530525.837363433\n",
      "Loss increases to 986597.2431482523\n",
      "The norm of gradient vector is 21702819.282385334\n",
      "Loss increases to 2148066.415128975\n",
      "The norm of gradient vector is 32436782.28985008\n",
      "Loss increases to 4749300.050310094\n",
      "The norm of gradient vector is 48489126.08735846\n",
      "Loss increases to 10566667.521620376\n",
      "The norm of gradient vector is 72489668.87087141\n",
      "Loss increases to 23571029.150794312\n",
      "The norm of gradient vector is 108371562.02016178\n",
      "Loss increases to 52637807.201138645\n",
      "The norm of gradient vector is 162015573.84262815\n",
      "Loss increases to 117604165.31338564\n",
      "The norm of gradient vector is 242213782.34230173\n",
      "Loss increases to 262807075.66459775\n",
      "The norm of gradient vector is 362110514.8812747\n",
      "Loss increases to 587341432.020934\n",
      "The norm of gradient vector is 541356653.8876424\n",
      "Loss increases to 1312688075.361999\n",
      "The norm of gradient vector is 809330374.6360586\n",
      "Loss increases to 2933864953.8462424\n",
      "The norm of gradient vector is 1209952179.8460054\n",
      "Loss increases to 6557255582.620218\n",
      "The norm of gradient vector is 1808883404.114141\n",
      "Loss increases to 14655668192.44725\n",
      "The norm of gradient vector is 2704288010.817552\n",
      "Loss increases to 32755920947.21981\n",
      "The norm of gradient vector is 4042921523.6618185\n",
      "Loss increases to 73210657525.51303\n",
      "The norm of gradient vector is 6044184045.194177\n",
      "Loss increases to 163628494900.30402\n",
      "The norm of gradient vector is 9036079617.175596\n",
      "Loss increases to 365715716428.50037\n",
      "The norm of gradient vector is 13508975610.059076\n",
      "Loss increases to 817388155028.0514\n",
      "The norm of gradient vector is 20195973227.96711\n",
      "Loss increases to 1826892814641.2754\n",
      "The norm of gradient vector is 30193061739.040657\n",
      "Loss increases to 4083173186589.7666\n",
      "The norm of gradient vector is 45138749536.267426\n",
      "Loss increases to 9126043537235.787\n",
      "The norm of gradient vector is 67482613300.661095\n",
      "Loss increases to 20397045886728.977\n",
      "The norm of gradient vector is 100886780087.43683\n",
      "Loss increases to 45588154348568.02\n",
      "The norm of gradient vector is 150826144670.24265\n",
      "Loss increases to 101891216477227.53\n",
      "The norm of gradient vector is 225485696900.7623\n",
      "Loss increases to 227730649460697.72\n",
      "The norm of gradient vector is 337102029744.14685\n",
      "Loss increases to 508986451452663.94\n",
      "The norm of gradient vector is 503968899223.07153\n",
      "Loss increases to 1137603604905121.0\n",
      "The norm of gradient vector is 753435544653.5992\n",
      "Loss increases to 2542586267719484.5\n",
      "The norm of gradient vector is 1126389189536.478\n",
      "Loss increases to 5682774651010586.0\n",
      "The norm of gradient vector is 1683956398537.0083\n",
      "Loss increases to 1.2701212204399228e+16\n",
      "The norm of gradient vector is 2517521633300.349\n",
      "Loss increases to 2.8387680555444504e+16\n",
      "The norm of gradient vector is 3763705033955.4688\n",
      "Loss increases to 6.344751936665398e+16\n",
      "The norm of gradient vector is 5626754263101.002\n",
      "Loss increases to 1.4180756000550698e+17\n",
      "The norm of gradient vector is 8412020403217.363\n",
      "Loss increases to 3.169451583837259e+17\n",
      "The norm of gradient vector is 12576004558824.826\n",
      "Loss increases to 7.083841892420347e+17\n",
      "The norm of gradient vector is 18801177729323.223\n",
      "Loss increases to 1.5832649475609636e+18\n",
      "The norm of gradient vector is 28107836821795.094\n",
      "Loss increases to 3.5386559048662994e+18\n",
      "The norm of gradient vector is 42021329842994.85\n",
      "Loss increases to 7.909027249252016e+18\n",
      "The norm of gradient vector is 62822058238382.734\n",
      "Loss increases to 1.7676969366642756e+19\n",
      "The norm of gradient vector is 93919231401113.53\n",
      "Loss increases to 3.950868243863722e+19\n",
      "The norm of gradient vector is 140409631176117.66\n",
      "Loss increases to 8.830337122055766e+19\n",
      "The norm of gradient vector is 209912967055857.5\n",
      "Loss increases to 1.973613111757464e+20\n",
      "The norm of gradient vector is 313820735579912.94\n",
      "Loss increases to 4.4110985357194966e+20\n",
      "The norm of gradient vector is 469163270193362.2\n",
      "Loss increases to 9.858968901204731e+20\n",
      "The norm of gradient vector is 701400988343802.1\n",
      "Loss increases to 2.203516131136886e+21\n",
      "The norm of gradient vector is 1048597317191738.9\n",
      "Loss increases to 4.924940314587203e+21\n",
      "The norm of gradient vector is 1567657234441688.5\n",
      "Loss increases to 1.1007424343080301e+22\n",
      "The norm of gradient vector is 2343653912141368.5\n",
      "Loss increases to 2.4602001837415645e+22\n",
      "The norm of gradient vector is 3503772086920353.0\n",
      "Loss increases to 5.498638696423949e+22\n",
      "The norm of gradient vector is 5238153454946506.0\n",
      "Loss increases to 1.228966151357176e+23\n",
      "The norm of gradient vector is 7831060621778319.0\n",
      "Loss increases to 2.7467849490891854e+23\n",
      "The norm of gradient vector is 1.170746733356121e+16\n",
      "Loss increases to 6.139166280707526e+23\n",
      "The norm of gradient vector is 1.7502711061286284e+16\n",
      "Loss increases to 1.372126443123034e+24\n",
      "The norm of gradient vector is 2.6166623896245244e+16\n",
      "Loss increases to 3.0667535131504706e+24\n",
      "The norm of gradient vector is 3.911920866030879e+16\n",
      "Loss increases to 6.854307893822461e+24\n",
      "The norm of gradient vector is 5.848337532104664e+16\n",
      "Loss increases to 1.531963247188161e+25\n",
      "The norm of gradient vector is 8.743288287456397e+16\n",
      "Loss increases to 3.4239947009828335e+25\n",
      "The norm of gradient vector is 1.3071251386898253e+17\n",
      "Loss increases to 7.6527552040669655e+25\n",
      "The norm of gradient vector is 1.9541573742296845e+17\n",
      "Loss increases to 1.7104191836676448e+26\n",
      "The norm of gradient vector is 2.921473185867954e+17\n",
      "Loss increases to 3.82285034062445e+26\n",
      "The norm of gradient vector is 4.3676142404395104e+17\n",
      "Loss increases to 8.54421235820995e+26\n",
      "The norm of gradient vector is 6.529600971717496e+17\n",
      "Loss increases to 1.9096631653715934e+27\n",
      "The norm of gradient vector is 9.761779887768584e+17\n",
      "Loss increases to 4.2681680326834487e+27\n",
      "The norm of gradient vector is 1.4593900452722186e+18\n",
      "Loss increases to 9.539513923480877e+27\n",
      "The norm of gradient vector is 2.1817940260139374e+18\n",
      "Loss increases to 2.1321167582774725e+28\n",
      "The norm of gradient vector is 3.261790901871051e+18\n",
      "Loss increases to 4.765360066971699e+28\n",
      "The norm of gradient vector is 4.876390603638402e+18\n",
      "Loss increases to 1.065075656843238e+29\n",
      "The norm of gradient vector is 7.290223694477937e+18\n",
      "Loss increases to 2.3804836126914864e+29\n",
      "The norm of gradient vector is 1.089891393767204e+19\n",
      "Loss increases to 5.3204692022425666e+29\n",
      "The norm of gradient vector is 1.6293920461008337e+19\n",
      "Loss increases to 1.1891446083094827e+30\n",
      "The norm of gradient vector is 2.435947705504811e+19\n",
      "Loss increases to 2.6577823227986916e+30\n",
      "The norm of gradient vector is 3.6417516816495747e+19\n",
      "Loss increases to 5.940242108504602e+30\n",
      "The norm of gradient vector is 5.444433507676264e+19\n",
      "Loss increases to 1.3276661525272672e+31\n",
      "The norm of gradient vector is 8.139450135732876e+19\n",
      "Loss increases to 2.9673831139692312e+31\n",
      "The norm of gradient vector is 1.2168510905436396e+20\n",
      "Loss increases to 6.632211364512364e+31\n",
      "The norm of gradient vector is 1.819197306777186e+20\n",
      "Loss increases to 1.4823238487978743e+32\n",
      "The norm of gradient vector is 2.7197073386414326e+20\n",
      "Loss increases to 3.313048803709981e+32\n",
      "The norm of gradient vector is 4.065973481988023e+20\n",
      "Loss increases to 7.404787007013109e+32\n",
      "The norm of gradient vector is 6.078646816641699e+20\n",
      "Loss increases to 1.654997371539774e+33\n",
      "The norm of gradient vector is 9.087601600245035e+20\n",
      "Loss increases to 3.698980534091556e+33\n",
      "The norm of gradient vector is 1.3586001183467674e+21\n",
      "Loss increases to 8.26735874441806e+33\n",
      "The norm of gradient vector is 2.0311126772129637e+21\n",
      "Loss increases to 1.8477853554233947e+34\n",
      "The norm of gradient vector is 3.0365216753810465e+21\n",
      "Loss increases to 4.129868831472239e+34\n",
      "The norm of gradient vector is 4.539612198034714e+21\n",
      "Loss increases to 9.230410077180073e+34\n",
      "The norm of gradient vector is 6.78673861465504e+21\n",
      "Loss increases to 2.063030901698994e+35\n",
      "The norm of gradient vector is 1.0146201704980443e+22\n",
      "Loss increases to 4.610950614087154e+35\n",
      "The norm of gradient vector is 1.5168612625783389e+22\n",
      "Loss increases to 1.0305645711870566e+36\n",
      "The norm of gradient vector is 2.26771372855847e+22\n",
      "Loss increases to 2.3033500557156147e+36\n",
      "The norm of gradient vector is 3.3902412050205338e+22\n",
      "Loss increases to 5.148072840359799e+36\n",
      "The norm of gradient vector is 5.0684243268771716e+22\n",
      "Loss increases to 1.150613381751748e+37\n",
      "The norm of gradient vector is 7.577314888167289e+22\n",
      "Loss increases to 2.5716636017404606e+37\n",
      "The norm of gradient vector is 1.1328116434524617e+23\n",
      "Loss increases to 5.747763571503133e+37\n",
      "The norm of gradient vector is 1.6935579931426707e+23\n",
      "Loss increases to 1.2846464853155637e+38\n",
      "The norm of gradient vector is 2.5318760561078154e+23\n",
      "Loss increases to 2.87123256150574e+38\n",
      "The norm of gradient vector is 3.7851649541664274e+23\n",
      "Loss increases to 6.4173113120888886e+38\n",
      "The norm of gradient vector is 5.658836930696746e+23\n",
      "Loss increases to 1.43429288969429e+39\n",
      "The norm of gradient vector is 8.459984121159493e+23\n",
      "Loss increases to 3.205697827924077e+39\n",
      "The norm of gradient vector is 1.2647710511329135e+24\n",
      "Loss increases to 7.164853592872172e+39\n",
      "The norm of gradient vector is 1.890837841861828e+24\n",
      "Loss increases to 1.6013713632060106e+40\n",
      "The norm of gradient vector is 2.8268102286292553e+24\n",
      "Loss increases to 3.5791244156718213e+40\n",
      "The norm of gradient vector is 4.226092736125232e+24\n",
      "Loss increases to 7.999475872487034e+40\n",
      "The norm of gradient vector is 6.318025749818678e+24\n",
      "Loss increases to 1.787912539567047e+41\n",
      "The norm of gradient vector is 9.445474074468816e+24\n",
      "Loss increases to 3.996050866451646e+41\n",
      "The norm of gradient vector is 1.4121021981276827e+25\n",
      "Loss increases to 8.931321960041628e+41\n",
      "The norm of gradient vector is 2.1110985030882864e+25\n",
      "Loss increases to 1.996183597751684e+42\n",
      "The norm of gradient vector is 3.1561008088867956e+25\n",
      "Loss increases to 4.461544409394777e+42\n",
      "The norm of gradient vector is 4.718383486741222e+25\n",
      "Loss increases to 9.971717300663809e+42\n",
      "The norm of gradient vector is 7.054002415025778e+25\n",
      "Loss increases to 2.2287158167690808e+43\n",
      "The norm of gradient vector is 1.0545762168550613e+26\n",
      "Loss increases to 4.981262547009843e+43\n",
      "The norm of gradient vector is 1.576595713643896e+26\n",
      "Loss increases to 1.113330662238211e+44\n",
      "The norm of gradient vector is 2.3570169747360498e+26\n",
      "Loss increases to 2.48833534025189e+44\n",
      "The norm of gradient vector is 3.5237499195996805e+26\n",
      "Loss increases to 5.56152181517989e+44\n",
      "The norm of gradient vector is 5.2680203956822354e+26\n",
      "Loss increases to 1.2430207617270263e+45\n",
      "The norm of gradient vector is 7.875711819094367e+26\n",
      "Loss increases to 2.7781975247623122e+45\n",
      "The norm of gradient vector is 1.1774221054318815e+27\n",
      "Loss increases to 6.209374552901022e+45\n",
      "The norm of gradient vector is 1.7602508144070956e+27\n",
      "Loss increases to 1.3878182524661716e+46\n",
      "The norm of gradient vector is 2.631582093903623e+27\n",
      "Loss increases to 3.101825289277181e+46\n",
      "The norm of gradient vector is 3.9342258843304643e+27\n",
      "Loss increases to 6.932694614804391e+46\n",
      "The norm of gradient vector is 5.881683624764276e+27\n",
      "Loss increases to 1.5494829701816558e+47\n",
      "The norm of gradient vector is 8.793140830983972e+27\n",
      "Loss increases to 3.463151931942855e+47\n",
      "The norm of gradient vector is 1.31457811412997e+28\n",
      "Loss increases to 7.740273068192198e+47\n",
      "The norm of gradient vector is 1.9652996026860262e+28\n",
      "Loss increases to 1.729979751034786e+48\n",
      "The norm of gradient vector is 2.93813086251943e+28\n",
      "Loss increases to 3.866568934485131e+48\n",
      "The norm of gradient vector is 4.392517534471973e+28\n",
      "Loss increases to 8.641925037667598e+48\n",
      "The norm of gradient vector is 6.566831497116868e+28\n",
      "Loss increases to 1.9315023117934107e+49\n",
      "The norm of gradient vector is 9.817439673968208e+28\n",
      "Loss increases to 4.316979335278037e+49\n",
      "The norm of gradient vector is 1.4677112058428953e+29\n",
      "Loss increases to 9.64860899592386e+49\n",
      "The norm of gradient vector is 2.1942341947552686e+29\n",
      "Loss increases to 2.1564999117658923e+50\n",
      "The norm of gradient vector is 3.28038900450329e+29\n",
      "Loss increases to 4.819857319755567e+50\n",
      "The norm of gradient vector is 4.904194842367909e+29\n",
      "Loss increases to 1.0772559950525633e+51\n",
      "The norm of gradient vector is 7.331791143943848e+29\n",
      "Loss increases to 2.407707120540947e+51\n",
      "The norm of gradient vector is 1.096105744290915e+30\n",
      "Loss increases to 5.381314752414737e+51\n",
      "The norm of gradient vector is 1.6386825252925426e+30\n",
      "Loss increases to 1.2027438145404607e+52\n",
      "The norm of gradient vector is 2.4498370095088663e+30\n",
      "Loss increases to 2.6881770533236607e+52\n",
      "The norm of gradient vector is 3.662516247366402e+30\n",
      "Loss increases to 6.008175459024801e+52\n",
      "The norm of gradient vector is 5.475476617488146e+30\n",
      "Loss increases to 1.3428495084353235e+53\n",
      "The norm of gradient vector is 8.185859710579489e+30\n",
      "Loss increases to 3.0013184778023704e+53\n",
      "The norm of gradient vector is 1.2237893407720975e+31\n",
      "Loss increases to 6.7080581618515696e+53\n",
      "The norm of gradient vector is 1.8295700189581957e+31\n",
      "Loss increases to 1.499275889432832e+54\n",
      "The norm of gradient vector is 2.7352145853459063e+31\n",
      "Loss increases to 3.3509372435348146e+54\n",
      "The norm of gradient vector is 4.089156878592208e+31\n",
      "Loss increases to 7.489469075872686e+54\n",
      "The norm of gradient vector is 6.113306088422798e+31\n",
      "Loss increases to 1.6739241281428213e+55\n",
      "The norm of gradient vector is 9.139417351875639e+31\n",
      "Loss increases to 3.7412825373769347e+55\n",
      "The norm of gradient vector is 1.3663465941931194e+32\n",
      "Loss increases to 8.3619052913773e+55\n",
      "The norm of gradient vector is 2.0426936899648216e+32\n",
      "Loss increases to 1.8689168594838758e+56\n",
      "The norm of gradient vector is 3.0538353363307343e+32\n",
      "Loss increases to 4.177098527132158e+56\n",
      "The norm of gradient vector is 4.56549619124875e+32\n",
      "Loss increases to 9.335970199438492e+56\n",
      "The norm of gradient vector is 6.825435289301216e+32\n",
      "Loss increases to 2.0866239807047287e+57\n",
      "The norm of gradient vector is 1.0204053390239732e+33\n",
      "Loss increases to 4.6636820210864846e+57\n",
      "The norm of gradient vector is 1.5255101129458215e+33\n",
      "Loss increases to 1.042350236311363e+58\n",
      "The norm of gradient vector is 2.2806437948726756e+33\n",
      "Loss increases to 2.3296914545757075e+58\n",
      "The norm of gradient vector is 3.40957170650757e+33\n",
      "Loss increases to 5.206946844210073e+58\n",
      "The norm of gradient vector is 5.097323504859713e+33\n",
      "Loss increases to 1.1637719400643573e+59\n",
      "The norm of gradient vector is 7.620519276249343e+33\n",
      "Loss increases to 2.601073467817633e+59\n",
      "The norm of gradient vector is 1.1392707169619999e+34\n",
      "Loss increases to 5.813495713439093e+59\n",
      "The norm of gradient vector is 1.7032143341889509e+34\n",
      "Loss increases to 1.2993378629374523e+60\n",
      "The norm of gradient vector is 2.5463123250656424e+34\n",
      "Loss increases to 2.904068335614426e+60\n",
      "The norm of gradient vector is 3.806747234703527e+34\n",
      "Loss increases to 6.490700485593648e+60\n",
      "The norm of gradient vector is 5.691102527475443e+34\n",
      "Loss increases to 1.450695642283231e+61\n",
      "The norm of gradient vector is 8.508221318970718e+34\n",
      "Loss increases to 3.242358588584717e+61\n",
      "The norm of gradient vector is 1.2719825317344919e+35\n",
      "Loss increases to 7.246791753246727e+61\n",
      "The norm of gradient vector is 1.9016190345568246e+35\n",
      "Loss increases to 1.6196848460813815e+62\n",
      "The norm of gradient vector is 2.842928155355871e+35\n",
      "Loss increases to 3.6200557294203057e+62\n",
      "The norm of gradient vector is 4.250189101834853e+35\n",
      "Loss increases to 8.090958877471854e+62\n",
      "The norm of gradient vector is 6.354049914108551e+35\n",
      "Loss increases to 1.808359330628967e+63\n",
      "The norm of gradient vector is 9.499330345925788e+35\n",
      "Loss increases to 4.041750203153495e+63\n",
      "The norm of gradient vector is 1.4201537325141792e+36\n",
      "Loss increases to 9.033461673244775e+63\n",
      "The norm of gradient vector is 2.123135579592687e+36\n",
      "Loss increases to 2.01901220264213e+64\n",
      "The norm of gradient vector is 3.1740962869929075e+36\n",
      "Loss increases to 4.5125671883806255e+64\n",
      "The norm of gradient vector is 4.745286799364448e+36\n",
      "Loss increases to 1.0085755104898099e+65\n",
      "The norm of gradient vector is 7.094222976315398e+36\n",
      "Loss increases to 2.254203689152869e+65\n",
      "The norm of gradient vector is 1.0605892070511293e+37\n",
      "Loss increases to 5.038228887515457e+65\n",
      "The norm of gradient vector is 1.5855851583305715e+37\n",
      "Loss increases to 1.1260628507148988e+66\n",
      "The norm of gradient vector is 2.370456230936343e+37\n",
      "Loss increases to 2.516792253925317e+66\n",
      "The norm of gradient vector is 3.5438416620278685e+37\n",
      "Loss increases to 5.62512407313417e+66\n",
      "The norm of gradient vector is 5.298057631953678e+37\n",
      "Loss increases to 1.2572361023760738e+67\n",
      "The norm of gradient vector is 7.920617608925747e+37\n",
      "Loss increases to 2.809969338573343e+67\n",
      "The norm of gradient vector is 1.1841355391917554e+38\n",
      "Loss increases to 6.280385735662262e+67\n",
      "The norm of gradient vector is 1.770287425057403e+38\n",
      "Loss increases to 1.4036895153003978e+68\n",
      "The norm of gradient vector is 2.6465868674589907e+38\n",
      "Loss increases to 3.1372981506151017e+68\n",
      "The norm of gradient vector is 3.956658081542476e+38\n",
      "Loss increases to 7.0119777761156525e+68\n",
      "The norm of gradient vector is 5.9152198504128515e+38\n",
      "Loss increases to 1.5672030509150012e+69\n",
      "The norm of gradient vector is 8.843277624099805e+38\n",
      "Loss increases to 3.502756969885723e+69\n",
      "The norm of gradient vector is 1.3220735849986387e+39\n",
      "Loss increases to 7.828791797539992e+69\n",
      "The norm of gradient vector is 1.9765053619800573e+39\n",
      "Loss increases to 1.7497640154928884e+70\n",
      "The norm of gradient vector is 2.954883518030458e+39\n",
      "Loss increases to 3.910787499644392e+70\n",
      "The norm of gradient vector is 4.417562822283986e+39\n",
      "Loss increases to 8.740755171529015e+70\n",
      "The norm of gradient vector is 6.604274303791524e+39\n",
      "Loss increases to 1.9535912134207815e+71\n",
      "The norm of gradient vector is 9.873416821533796e+39\n",
      "Loss increases to 4.366348850024207e+71\n",
      "The norm of gradient vector is 1.4760798120662652e+40\n",
      "Loss increases to 9.758951693238057e+71\n",
      "The norm of gradient vector is 2.206745294939458e+40\n",
      "Loss increases to 2.1811619140423445e+72\n",
      "The norm of gradient vector is 3.299093149929768e+40\n",
      "Loss increases to 4.874977809927366e+72\n",
      "The norm of gradient vector is 4.932157615504114e+40\n",
      "Loss increases to 1.0895756291306142e+73\n",
      "The norm of gradient vector is 7.373595602989594e+40\n",
      "Loss increases to 2.4352419598255807e+73\n",
      "The norm of gradient vector is 1.1023555278427647e+41\n",
      "Loss increases to 5.442856139896483e+73\n",
      "The norm of gradient vector is 1.6480259770047698e+41\n",
      "Loss increases to 1.2164985429920348e+74\n",
      "The norm of gradient vector is 2.4638055076455545e+41\n",
      "Loss increases to 2.718919381782315e+74\n",
      "The norm of gradient vector is 3.683399208632134e+41\n",
      "Loss increases to 6.076885703824414e+74\n",
      "The norm of gradient vector is 5.50669672912496e+41\n",
      "Loss increases to 1.358206503097495e+75\n",
      "The norm of gradient vector is 8.232533903870968e+41\n",
      "Loss increases to 3.035641930693824e+75\n",
      "The norm of gradient vector is 1.2307671515651935e+42\n",
      "Loss increases to 6.784772352636159e+75\n",
      "The norm of gradient vector is 1.8400018743435e+42\n",
      "Loss increases to 1.516421795721298e+76\n",
      "The norm of gradient vector is 2.7508102513802422e+42\n",
      "Loss increases to 3.389258980288627e+76\n",
      "The norm of gradient vector is 4.1124724624525e+42\n",
      "Loss increases to 7.575119579446015e+76\n",
      "The norm of gradient vector is 6.148162980686938e+42\n",
      "Loss increases to 1.693067333497771e+77\n",
      "The norm of gradient vector is 9.191528546928448e+42\n",
      "Loss increases to 3.784068311654145e+77\n",
      "The norm of gradient vector is 1.3741372389507012e+43\n",
      "Loss increases to 8.457533084453608e+77\n",
      "The norm of gradient vector is 2.0543407354177856e+43\n",
      "Loss increases to 1.890290026063488e+78\n",
      "The norm of gradient vector is 3.071247716435911e+43\n",
      "Loss increases to 4.224868347489237e+78\n",
      "The norm of gradient vector is 4.591527769999909e+43\n",
      "Loss increases to 9.442737520436408e+78\n",
      "The norm of gradient vector is 6.864352604922893e+43\n",
      "Loss increases to 2.1104868731080523e+79\n",
      "The norm of gradient vector is 1.0262234934650656e+44\n",
      "Loss increases to 4.717016471040861e+79\n",
      "The norm of gradient vector is 1.534208277390019e+44\n",
      "Loss increases to 1.0542706837737172e+80\n",
      "The norm of gradient vector is 2.2936475859312184e+44\n",
      "Loss increases to 2.3563340969624337e+80\n",
      "The norm of gradient vector is 3.4290124267858606e+44\n",
      "Loss increases to 5.266494138520014e+80\n",
      "The norm of gradient vector is 5.126387460381397e+44\n",
      "Loss increases to 1.177080981292945e+81\n",
      "The norm of gradient vector is 7.663970007419514e+44\n",
      "Loss increases to 2.630819668795685e+81\n",
      "The norm of gradient vector is 1.1457666188629435e+45\n",
      "Loss increases to 5.879979576358241e+81\n",
      "The norm of gradient vector is 1.7129257338294825e+45\n",
      "Loss increases to 1.3141972529883474e+82\n",
      "The norm of gradient vector is 2.5608309068447832e+45\n",
      "Loss increases to 2.9372796237360506e+82\n",
      "The norm of gradient vector is 3.8284525732417355e+45\n",
      "Loss increases to 6.564928946850784e+82\n",
      "The norm of gradient vector is 5.723552096464e+45\n",
      "Loss increases to 1.4672859787990086e+83\n",
      "The norm of gradient vector is 8.556733555980499e+45\n",
      "Loss increases to 3.279438606282144e+83\n",
      "The norm of gradient vector is 1.279235130807605e+46\n",
      "Loss increases to 7.329666968655041e+83\n",
      "The norm of gradient vector is 1.9124616995332332e+46\n",
      "Loss increases to 1.6382077642337392e+84\n",
      "The norm of gradient vector is 2.859137983392067e+46\n",
      "Loss increases to 3.661455138783962e+84\n",
      "The norm of gradient vector is 4.2744228603743603e+46\n",
      "Loss increases to 8.183488093525287e+84\n",
      "The norm of gradient vector is 6.390279481235347e+46\n",
      "Loss increases to 1.8290399537466934e+85\n",
      "The norm of gradient vector is 9.553493695455542e+46\n",
      "Loss increases to 4.0879721631764264e+85\n",
      "The norm of gradient vector is 1.4282511751968781e+47\n",
      "Loss increases to 9.136769468962478e+85\n",
      "The norm of gradient vector is 2.13524128918577e+47\n",
      "Loss increases to 2.0421018783087555e+86\n",
      "The norm of gradient vector is 3.192194371844461e+47\n",
      "Loss increases to 4.5641734702382644e+86\n",
      "The norm of gradient vector is 4.772343509487509e+47\n",
      "Loss increases to 1.0201097059701714e+87\n",
      "The norm of gradient vector is 7.134672867488309e+47\n",
      "Loss increases to 2.2799830440279626e+87\n",
      "The norm of gradient vector is 1.0666364821575941e+48\n",
      "Loss increases to 5.095846702204605e+87\n",
      "The norm of gradient vector is 1.5946258590970946e+48\n",
      "Loss increases to 1.1389406460889056e+88\n",
      "The norm of gradient vector is 2.3839721151835192e+48\n",
      "Loss increases to 2.545574604416993e+88\n",
      "The norm of gradient vector is 3.564047963696373e+48\n",
      "Loss increases to 5.689453694452576e+88\n",
      "The norm of gradient vector is 5.3282661347531844e+48\n",
      "Loss increases to 1.2716140114358847e+89\n",
      "The norm of gradient vector is 7.965779442909953e+48\n",
      "Loss increases to 2.8421044988145336e+89\n",
      "The norm of gradient vector is 1.1908872516561357e+49\n",
      "Loss increases to 6.352209011176881e+89\n",
      "The norm of gradient vector is 1.78038126252592e+49\n",
      "Loss increases to 1.4197422838782796e+90\n",
      "The norm of gradient vector is 2.661677195339266e+49\n",
      "Loss increases to 3.1731766840248676e+90\n",
      "The norm of gradient vector is 3.9792181828165916e+49\n",
      "Loss increases to 7.092167629559952e+90\n",
      "The norm of gradient vector is 5.948947293152092e+49\n",
      "Loss increases to 1.5851257807043646e+91\n",
      "The norm of gradient vector is 8.893700287540323e+49\n",
      "Loss increases to 3.542814935988085e+91\n",
      "The norm of gradient vector is 1.329611793596582e+50\n",
      "Loss increases to 7.918322838130154e+91\n",
      "The norm of gradient vector is 1.9877750143523753e+50\n",
      "Loss increases to 1.769774535269838e+92\n",
      "The norm of gradient vector is 2.971731693952194e+50\n",
      "Loss increases to 3.955511753836484e+92\n",
      "The norm of gradient vector is 4.442750913496721e+50\n",
      "Loss increases to 8.840715539142402e+92\n",
      "The norm of gradient vector is 6.641930602128401e+50\n",
      "Loss increases to 1.9759327264854557e+93\n",
      "The norm of gradient vector is 9.92971313999873e+50\n",
      "Loss increases to 4.416282960705903e+93\n",
      "The norm of gradient vector is 1.4844961344683042e+51\n",
      "Loss increases to 9.870556283417512e+93\n",
      "The norm of gradient vector is 2.2193277310039385e+51\n",
      "Loss increases to 2.2061059540564383e+94\n",
      "The norm of gradient vector is 3.317903942786085e+51\n",
      "Loss increases to 4.930728664907816e+94\n",
      "The norm of gradient vector is 4.960279826979693e+51\n",
      "Loss increases to 1.1020361520823685e+95\n",
      "The norm of gradient vector is 7.415638422998194e+51\n",
      "Loss increases to 2.4630916909706287e+95\n",
      "The norm of gradient vector is 1.1086409464550604e+52\n",
      "Loss increases to 5.505101322370313e+95\n",
      "The norm of gradient vector is 1.657422703276632e+52\n",
      "Loss increases to 1.230410572235771e+96\n",
      "The norm of gradient vector is 2.47785365146458e+52\n",
      "Loss increases to 2.750013283348104e+96\n",
      "The norm of gradient vector is 3.7044012405154055e+52\n",
      "Loss increases to 6.146381727563601e+96\n",
      "The norm of gradient vector is 5.538094851817053e+52\n",
      "Loss increases to 1.3737391222682933e+97\n",
      "The norm of gradient vector is 8.279474224410757e+52\n",
      "Loss increases to 3.0703579108786024e+97\n",
      "The norm of gradient vector is 1.237784748489652e+53\n",
      "Loss increases to 6.862363856486052e+97\n",
      "The norm of gradient vector is 1.8504932101562656e+53\n",
      "Loss increases to 1.533763784735132e+98\n",
      "The norm of gradient vector is 2.7664948408944368e+53\n",
      "Loss increases to 3.4280189692092815e+98\n",
      "The norm of gradient vector is 4.135920987275191e+53\n",
      "Loss increases to 7.661749592873611e+98\n",
      "The norm of gradient vector is 6.183218620228076e+53\n",
      "Loss increases to 1.7124294629396223e+99\n",
      "The norm of gradient vector is 9.243936869964995e+53\n",
      "Loss increases to 3.827343389388756e+99\n",
      "The norm of gradient vector is 1.3819723044621423e+54\n",
      "Loss increases to 8.554254488912801e+99\n",
      "The norm of gradient vector is 2.066054190077606e+54\n",
      "Loss increases to 1.911907618845022e+100\n",
      "The norm of gradient vector is 3.0887593785741944e+54\n",
      "Loss increases to 4.2731844694770365e+100\n",
      "The norm of gradient vector is 4.617707775792501e+54\n",
      "Loss increases to 9.550725845849511e+100\n",
      "The norm of gradient vector is 6.903491819572415e+54\n",
      "Loss increases to 2.1346226645287093e+101\n",
      "The norm of gradient vector is 1.0320748219006571e+55\n",
      "Loss increases to 4.770960860424901e+101\n",
      "The norm of gradient vector is 1.542956037090296e+55\n",
      "Loss increases to 1.0663274549617789e+102\n",
      "The norm of gradient vector is 2.3067255220983863e+55\n",
      "Loss increases to 2.383281427934415e+102\n",
      "The norm of gradient vector is 3.4485639943017245e+55\n",
      "Loss increases to 5.326722423123478e+102\n",
      "The norm of gradient vector is 5.15561713297202e+55\n",
      "Loss increases to 1.190542226378952e+103\n",
      "The norm of gradient vector is 7.707668486278647e+55\n",
      "Loss increases to 2.6609060510425896e+103\n",
      "The norm of gradient vector is 1.152299559143687e+56\n",
      "Loss increases to 5.947223757035697e+103\n",
      "The norm of gradient vector is 1.7226925059977637e+56\n",
      "Loss increases to 1.3292265768793824e+104\n",
      "The norm of gradient vector is 2.5754322707770814e+56\n",
      "Loss increases to 2.9708707202957823e+104\n",
      "The norm of gradient vector is 3.850281671434058e+56\n",
      "Loss increases to 6.640006294059881e+104\n",
      "The norm of gradient vector is 5.756186686636496e+56\n",
      "Loss increases to 1.4840660444748413e+105\n",
      "The norm of gradient vector is 8.605522400409329e+56\n",
      "Loss increases to 3.3169426756922025e+105\n",
      "The norm of gradient vector is 1.2865290828018506e+57\n",
      "Loss increases to 7.413489955375535e+105\n",
      "The norm of gradient vector is 1.9233661872941524e+57\n",
      "Loss increases to 1.6569425127910772e+106\n",
      "The norm of gradient vector is 2.8754402367413947e+57\n",
      "Loss increases to 3.7033279969627135e+106\n",
      "The norm of gradient vector is 4.2987947951311826e+57\n",
      "Loss increases to 8.27707548524778e+106\n",
      "The norm of gradient vector is 6.42671562236643e+57\n",
      "Loss increases to 1.849957083052815e+107\n",
      "The norm of gradient vector is 9.607965873958015e+57\n",
      "Loss increases to 4.13472272330598e+107\n",
      "The norm of gradient vector is 1.436394787936027e+58\n",
      "Loss increases to 9.241258705532208e+107\n",
      "The norm of gradient vector is 2.1474160232001658e+58\n",
      "Loss increases to 2.065455610389544e+108\n",
      "The norm of gradient vector is 3.21039564848532e+58\n",
      "Loss increases to 4.6163699279793755e+108\n",
      "The norm of gradient vector is 4.7995544917533536e+58\n",
      "Loss increases to 1.0317758079503372e+109\n",
      "The norm of gradient vector is 7.175353396139245e+58\n",
      "Loss increases to 2.3060572148245067e+109\n",
      "The norm of gradient vector is 1.0727182376603972e+59\n",
      "Loss increases to 5.154123441417347e+109\n",
      "The norm of gradient vector is 1.6037181081957366e+59\n",
      "Loss increases to 1.1519657135388745e+110\n",
      "The norm of gradient vector is 2.397565064395906e+59\n",
      "Loss increases to 2.5746861134629832e+110\n",
      "The norm of gradient vector is 3.584369477799868e+59\n",
      "Loss increases to 5.7545189973533103e+110\n",
      "The norm of gradient vector is 5.358646880609439e+59\n",
      "Loss increases to 1.2861563480590944e+111\n",
      "The norm of gradient vector is 8.011198780961324e+59\n",
      "Loss increases to 2.8746071607610046e+111\n",
      "The norm of gradient vector is 1.1976774610828075e+60\n",
      "Loss increases to 6.42485366663896e+111\n",
      "The norm of gradient vector is 1.7905326531089175e+60\n",
      "Loss increases to 1.4359786339221479e+112\n",
      "The norm of gradient vector is 2.676853565358691e+60\n",
      "Loss increases to 3.2094655288229015e+112\n",
      "The norm of gradient vector is 4.0019069174370745e+60\n",
      "Loss increases to 7.173274544181635e+112\n",
      "The norm of gradient vector is 5.982867043264921e+60\n",
      "Loss increases to 1.6032534770696294e+113\n",
      "The norm of gradient vector is 8.944410451282912e+60\n",
      "Loss increases to 3.5833310099928724e+113\n",
      "The norm of gradient vector is 1.337192983606078e+61\n",
      "Loss increases to 8.008877766880326e+113\n",
      "The norm of gradient vector is 1.9991089241089745e+61\n",
      "Loss increases to 1.7900138978496897e+114\n",
      "The norm of gradient vector is 2.988675934923576e+61\n",
      "Loss increases to 4.000747480184278e+114\n",
      "The norm of gradient vector is 4.468082622347596e+61\n",
      "Loss increases to 8.941819066001958e+114\n",
      "The norm of gradient vector is 6.679801609415733e+61\n",
      "Loss increases to 1.998529739883344e+115\n",
      "The norm of gradient vector is 9.986330449213844e+61\n",
      "Loss increases to 4.4667881241126775e+115\n",
      "The norm of gradient vector is 1.4929604451174479e+62\n",
      "Loss increases to 9.983437197626429e+115\n",
      "The norm of gradient vector is 2.2319819096921188e+62\n",
      "Loss increases to 2.2313352572269157e+116\n",
      "The norm of gradient vector is 3.336821991155281e+62\n",
      "Loss increases to 4.9871170936274666e+116\n",
      "The norm of gradient vector is 4.988562385881246e+62\n",
      "Loss increases to 1.1146391751305538e+117\n",
      "The norm of gradient vector is 7.457920963057789e+62\n",
      "Loss increases to 2.4912599151186635e+117\n",
      "The norm of gradient vector is 1.1149622033120317e+63\n",
      "Loss increases to 5.568058348523522e+117\n",
      "The norm of gradient vector is 1.666873007869375e+63\n",
      "Loss increases to 1.2444817011831442e+118\n",
      "The norm of gradient vector is 2.491981895090233e+63\n",
      "Loss increases to 2.7814627786549146e+118\n",
      "The norm of gradient vector is 3.725523021933866e+63\n",
      "Loss increases to 6.216672516508268e+118\n",
      "The norm of gradient vector is 5.569672000549054e+63\n",
      "Loss increases to 1.389449374411494e+119\n",
      "The norm of gradient vector is 8.326682189604999e+63\n",
      "Loss increases to 3.105470907347779e+119\n",
      "The norm of gradient vector is 1.2448423583983081e+64\n",
      "Loss increases to 6.940842706462874e+119\n",
      "The norm of gradient vector is 1.8610443655423976e+64\n",
      "Loss increases to 1.5513040989008306e+120\n",
      "The norm of gradient vector is 2.782268860912994e+64\n",
      "Loss increases to 3.4672222222032176e+120\n",
      "The norm of gradient vector is 4.159503211063958e+64\n",
      "Loss increases to 7.749370317952282e+120\n",
      "The norm of gradient vector is 6.218474140264774e+64\n",
      "Loss increases to 1.7320130201115251e+121\n",
      "The norm of gradient vector is 9.296644015151622e+64\n",
      "Loss increases to 3.8711133663161156e+121\n",
      "The norm of gradient vector is 1.3898520440060001e+65\n",
      "Loss increases to 8.652082011431055e+121\n",
      "The norm of gradient vector is 2.0778344325967528e+65\n",
      "Loss increases to 1.9337724331170082e+122\n",
      "The norm of gradient vector is 3.1063708888325597e+65\n",
      "Loss increases to 4.3220531406691555e+122\n",
      "The norm of gradient vector is 4.644037054928853e+65\n",
      "Loss increases to 9.659949139236607e+122\n",
      "The norm of gradient vector is 6.942854198475195e+65\n",
      "Loss increases to 2.15903447587391e+123\n",
      "The norm of gradient vector is 1.037959513482459e+66\n",
      "Loss increases to 4.82552216458202e+123\n",
      "The norm of gradient vector is 1.5517536748292294e+66\n",
      "Loss increases to 1.0785221088906896e+124\n",
      "The norm of gradient vector is 2.3198780261352756e+66\n",
      "Loss increases to 2.4105369319483296e+124\n",
      "The norm of gradient vector is 3.46822704108471e+66\n",
      "Loss increases to 5.387639485910431e+124\n",
      "The norm of gradient vector is 5.185013467518311e+66\n",
      "Loss increases to 1.2041574159446801e+125\n",
      "The norm of gradient vector is 7.75161612543624e+66\n",
      "Loss increases to 2.6913365049137913e+125\n",
      "The norm of gradient vector is 1.158869748989923e+67\n",
      "Loss increases to 6.015236950560243e+125\n",
      "The norm of gradient vector is 1.7325149664172625e+67\n",
      "Loss increases to 1.3444277779951682e+126\n",
      "The norm of gradient vector is 2.5901168888704054e+67\n",
      "Loss increases to 3.0048459688303364e+126\n",
      "The norm of gradient vector is 3.872235234934164e+67\n",
      "Loss increases to 6.715942235186664e+126\n",
      "The norm of gradient vector is 5.789007352948027e+67\n",
      "Loss increases to 1.5010380090770923e+127\n",
      "The norm of gradient vector is 8.654589429419341e+67\n",
      "Loss increases to 3.354875646323212e+127\n",
      "The norm of gradient vector is 1.2938646235036056e+68\n",
      "Loss increases to 7.498271552239242e+127\n",
      "The norm of gradient vector is 1.9343328503411678e+68\n",
      "Loss increases to 1.6758915142723435e+128\n",
      "The norm of gradient vector is 2.8918354423951534e+68\n",
      "Loss increases to 3.7456797183763076e+128\n",
      "The norm of gradient vector is 4.323305693959445e+68\n",
      "Loss increases to 8.371733154068356e+128\n",
      "The norm of gradient vector is 6.46335951534691e+68\n",
      "Loss increases to 1.8711134232616242e+129\n",
      "The norm of gradient vector is 9.66274864231641e+68\n",
      "Loss increases to 4.182007928678954e+129\n",
      "The norm of gradient vector is 1.444584833984378e+69\n",
      "Loss increases to 9.346942894059001e+129\n",
      "The norm of gradient vector is 2.1596601751998044e+69\n",
      "Loss increases to 2.089076418666611e+130\n",
      "The norm of gradient vector is 3.2287007052951573e+69\n",
      "Loss increases to 4.669163310929037e+130\n",
      "The norm of gradient vector is 4.8269206257919775e+69\n",
      "Loss increases to 1.0435753249295075e+131\n",
      "The norm of gradient vector is 7.216265877318623e+69\n",
      "Loss increases to 2.332429573094192e+131\n",
      "The norm of gradient vector is 1.0788346701601078e+70\n",
      "Loss increases to 5.213066640696806e+131\n",
      "The norm of gradient vector is 1.6128621995451446e+70\n",
      "Loss increases to 1.1651397372866547e+132\n",
      "The norm of gradient vector is 2.4112355179830692e+70\n",
      "Loss increases to 2.6041305453616005e+132\n",
      "The norm of gradient vector is 3.604806861257426e+70\n",
      "Loss increases to 5.820328395182769e+132\n",
      "The norm of gradient vector is 5.389200851619117e+70\n",
      "Loss increases to 1.3008649926598404e+133\n",
      "The norm of gradient vector is 8.056877091318362e+70\n",
      "Loss increases to 2.9074815272081317e+133\n",
      "The norm of gradient vector is 1.204506386974022e+71\n",
      "Loss increases to 6.498329095452109e+133\n",
      "The norm of gradient vector is 1.8007419249631486e+71\n",
      "Loss increases to 1.4524006648925645e+134\n",
      "The norm of gradient vector is 2.6921164681129426e+71\n",
      "Loss increases to 3.246169377381466e+134\n",
      "The norm of gradient vector is 4.024725018846452e+71\n",
      "Loss increases to 7.255309007606832e+134\n",
      "The norm of gradient vector is 6.016980197250888e+71\n",
      "Loss increases to 1.6215884840341488e+135\n",
      "The norm of gradient vector is 8.995409754598834e+71\n",
      "Loss increases to 3.62431043087926e+135\n",
      "The norm of gradient vector is 1.3448174000988464e+72\n",
      "Loss increases to 8.100468293103381e+135\n",
      "The norm of gradient vector is 2.010507457633069e+72\n",
      "Loss increases to 1.810484720307314e+136\n",
      "The norm of gradient vector is 3.005716788688993e+72\n",
      "Loss increases to 4.0465005279472215e+136\n",
      "The norm of gradient vector is 4.493558767716692e+72\n",
      "Loss increases to 9.044078825419613e+136\n",
      "The norm of gradient vector is 6.7178885498825555e+72\n",
      "Loss increases to 2.021385175548164e+137\n",
      "The norm of gradient vector is 1.0043270579406488e+73\n",
      "Loss increases to 4.517870870874796e+137\n",
      "The norm of gradient vector is 1.5014730176334255e+73\n",
      "Loss increases to 1.0097609032065779e+138\n",
      "The norm of gradient vector is 2.2447082400666052e+73\n",
      "Loss increases to 2.256853085858861e+138\n",
      "The norm of gradient vector is 3.355847906587613e+73\n",
      "Loss increases to 5.044150387459253e+138\n",
      "The norm of gradient vector is 5.017006206478891e+73\n",
      "Loss increases to 1.1273863279240724e+139\n",
      "The norm of gradient vector is 7.500444590005908e+73\n",
      "Loss increases to 2.519750274595458e+139\n",
      "The norm of gradient vector is 1.1213195027564404e+74\n",
      "Loss increases to 5.631735359089335e+139\n",
      "The norm of gradient vector is 1.676377196276255e+74\n",
      "Loss increases to 1.2587137493182375e+140\n",
      "The norm of gradient vector is 2.506190695236169e+74\n",
      "Loss increases to 2.8132719343171904e+140\n",
      "The norm of gradient vector is 3.7467652356762854e+74\n",
      "Loss increases to 6.287767159692623e+140\n",
      "The norm of gradient vector is 5.601429196092952e+74\n",
      "Loss increases to 1.4053392909599699e+141\n",
      "The norm of gradient vector is 8.374159325511948e+74\n",
      "Loss increases to 3.140985460429196e+141\n",
      "The norm of gradient vector is 1.2519402094374883e+75\n",
      "Loss increases to 7.020219050367833e+141\n",
      "The norm of gradient vector is 1.8716556815815815e+75\n",
      "Loss increases to 1.569045006289624e+142\n",
      "The norm of gradient vector is 2.7981328213514244e+75\n",
      "Loss increases to 3.5068738084937784e+142\n",
      "The norm of gradient vector is 4.183219896144561e+75\n",
      "Loss increases to 7.837993084584342e+142\n",
      "The norm of gradient vector is 6.253930680477133e+75\n",
      "Loss increases to 1.7518205372886874e+143\n",
      "The norm of gradient vector is 9.349651686314696e+75\n",
      "Loss increases to 3.915383902165272e+143\n",
      "The norm of gradient vector is 1.397776712305004e+76\n",
      "Loss increases to 8.751028301712758e+143\n",
      "The norm of gradient vector is 2.089681843786737e+76\n",
      "Loss increases to 1.955887296135316e+144\n",
      "The norm of gradient vector is 3.124082816525761e+76\n",
      "Loss increases to 4.3714806800873704e+144\n",
      "The norm of gradient vector is 4.6705164585368244e+76\n",
      "Loss increases to 9.770421523845857e+144\n",
      "The norm of gradient vector is 6.982441014070821e+76\n",
      "Loss increases to 2.1837254637420095e+145\n",
      "The norm of gradient vector is 1.0438777584407038e+77\n",
      "Loss increases to 4.8807074386266663e+145\n",
      "The norm of gradient vector is 1.5606014750017853e+77\n",
      "Loss increases to 1.090856222404703e+146\n",
      "The norm of gradient vector is 2.333105523213514e+77\n",
      "Loss increases to 2.438104133309604e+146\n",
      "The norm of gradient vector is 3.48800220276812e+77\n",
      "Loss increases to 5.449253203834262e+146\n",
      "The norm of gradient vector is 5.214577414294634e+77\n",
      "Loss increases to 1.2179283105184416e+147\n",
      "The norm of gradient vector is 7.795814345556309e+77\n",
      "Loss increases to 2.7221149652553803e+147\n",
      "The norm of gradient vector is 1.1654774007914968e+78\n",
      "Loss increases to 6.084027951458888e+147\n",
      "The norm of gradient vector is 1.7423934326116539e+78\n",
      "Loss increases to 1.3598028219451172e+148\n",
      "The norm of gradient vector is 2.6048852358239325e+78\n",
      "Loss increases to 3.039209762549689e+148\n",
      "The norm of gradient vector is 3.8943139734192544e+78\n",
      "Loss increases to 6.792746589218469e+148\n",
      "The norm of gradient vector is 5.822015156368882e+78\n",
      "Loss increases to 1.5182040671858616e+149\n",
      "The norm of gradient vector is 8.703936229165418e+78\n",
      "Loss increases to 3.393242423143135e+149\n",
      "The norm of gradient vector is 1.301241990043667e+79\n",
      "Loss increases to 7.5840227220315535e+149\n",
      "The norm of gradient vector is 1.9453620431857868e+79\n",
      "Loss increases to 1.695057218900764e+150\n",
      "The norm of gradient vector is 2.908324130349482e+79\n",
      "Loss increases to 3.788515779364558e+150\n",
      "The norm of gradient vector is 4.347956349205521e+79\n",
      "Loss increases to 8.467473339809725e+150\n",
      "The norm of gradient vector is 6.500212344737825e+79\n",
      "Loss increases to 1.8925117100189098e+151\n",
      "The norm of gradient vector is 9.71784377145429e+79\n",
      "Loss increases to 4.229833893565211e+151\n",
      "The norm of gradient vector is 1.452821578095721e+80\n",
      "Loss increases to 9.453835700162859e+151\n",
      "The norm of gradient vector is 2.1719741409926713e+80\n",
      "Loss increases to 2.1129673574567267e+152\n",
      "The norm of gradient vector is 3.2471101340085105e+80\n",
      "Loss increases to 4.722560445598551e+152\n",
      "The norm of gradient vector is 4.854442796248901e+80\n",
      "Loss increases to 1.0555097826582841e+153\n",
      "The norm of gradient vector is 7.257411633575062e+80\n",
      "Loss increases to 2.3591035289462222e+153\n",
      "The norm of gradient vector is 1.0849859773782808e+81\n",
      "Loss increases to 5.272683921763599e+153\n",
      "The norm of gradient vector is 1.6220584287398447e+81\n",
      "Loss increases to 1.1784644208150867e+154\n",
      "The norm of gradient vector is 2.4249839178600256e+81\n",
      "Loss increases to 2.633911707460209e+154\n",
      "The norm of gradient vector is 3.625360774733791e+81\n",
      "Loss increases to 5.886890397503587e+154\n",
      "The norm of gradient vector is 5.419929035478677e+81\n",
      "Loss increases to 1.3157418471569426e+155\n",
      "The norm of gradient vector is 8.102815850591277e+81\n",
      "Loss increases to 2.9407318490150486e+155\n",
      "The norm of gradient vector is 1.2113742500836022e+82\n",
      "Loss increases to 6.5726447984442115e+155\n",
      "The norm of gradient vector is 1.8110094081164745e+82\n",
      "Loss increases to 1.4690105002598188e+156\n",
      "The norm of gradient vector is 2.707466396995011e+82\n",
      "Loss increases to 3.283292975735452e+156\n",
      "The norm of gradient vector is 4.04767322466924e+82\n",
      "Loss increases to 7.338281627399608e+156\n",
      "The norm of gradient vector is 6.051287857861634e+82\n",
      "Loss increases to 1.6401331724278552e+157\n",
      "The norm of gradient vector is 9.046699846106259e+82\n",
      "Loss increases to 3.665758497540109e+157\n",
      "The norm of gradient vector is 1.3524852895439693e+83\n",
      "Loss increases to 8.193106260021457e+157\n",
      "The norm of gradient vector is 2.021970983396932e+83\n",
      "Loss increases to 1.831189649646807e+158\n",
      "The norm of gradient vector is 3.0228548061159844e+83\n",
      "Loss increases to 4.0927768132776725e+158\n",
      "The norm of gradient vector is 4.5191801731532077e+83\n",
      "Loss increases to 9.147508040215385e+158\n",
      "The norm of gradient vector is 6.756192654738259e+83\n",
      "Loss increases to 2.0445019888292647e+159\n",
      "The norm of gradient vector is 1.0100535371239713e+84\n",
      "Loss increases to 4.5695378063077336e+159\n",
      "The norm of gradient vector is 1.5100341271961098e+84\n",
      "Loss increases to 1.0213086549860743e+160\n",
      "The norm of gradient vector is 2.2575071335224194e+84\n",
      "Loss increases to 2.282662739565521e+160\n",
      "The norm of gradient vector is 3.3749823041202988e+84\n",
      "Loss increases to 5.1018359211611914e+160\n",
      "The norm of gradient vector is 5.04561220825575e+84\n",
      "Loss increases to 1.1402792587487076e+161\n",
      "The norm of gradient vector is 7.543210678473538e+84\n",
      "Loss increases to 2.548566453380891e+161\n",
      "The norm of gradient vector is 1.1277130502961767e+85\n",
      "Loss increases to 5.696140587899482e+161\n",
      "The norm of gradient vector is 1.6859355757324003e+85\n",
      "Loss increases to 1.2731085569329968e+162\n",
      "The norm of gradient vector is 2.5204805112201486e+85\n",
      "Loss increases to 2.8454448634557073e+162\n",
      "The norm of gradient vector is 3.768128568424569e+85\n",
      "Loss increases to 6.359674850094183e+162\n",
      "The norm of gradient vector is 5.633367465040961e+85\n",
      "Loss increases to 1.4214109265783005e+163\n",
      "The norm of gradient vector is 8.421907166891111e+85\n",
      "Loss increases to 3.176906162374425e+163\n",
      "The norm of gradient vector is 1.259078531054358e+86\n",
      "Loss increases to 7.100503152053551e+163\n",
      "The norm of gradient vector is 1.8823275012982537e+86\n",
      "Loss increases to 1.5869888009106501e+164\n",
      "The norm of gradient vector is 2.8140872350326486e+86\n",
      "Loss increases to 3.5469788552765193e+164\n",
      "The norm of gradient vector is 4.2070718091893414e+86\n",
      "Loss increases to 7.927629352242079e+164\n",
      "The norm of gradient vector is 6.28958938704341e+86\n",
      "Loss increases to 1.7718545757056855e+165\n",
      "The norm of gradient vector is 9.402961596995342e+86\n",
      "Loss increases to 3.960160721390534e+165\n",
      "The norm of gradient vector is 1.4057465655342472e+87\n",
      "Loss increases to 8.851106154125724e+165\n",
      "The norm of gradient vector is 2.1015968066303592e+87\n",
      "Loss increases to 1.9782550674886207e+166\n",
      "The norm of gradient vector is 3.141895734214631e+87\n",
      "Loss increases to 4.421473479018466e+166\n",
      "The norm of gradient vector is 4.697146842597173e+87\n",
      "Loss increases to 9.882157284440315e+166\n",
      "The norm of gradient vector is 7.022253546053993e+87\n",
      "Loss increases to 2.2086988208305668e+167\n",
      "The norm of gradient vector is 1.0498297480902683e+88\n",
      "Loss increases to 4.936523818356349e+167\n",
      "The norm of gradient vector is 1.5694997236244793e+88\n",
      "Loss increases to 1.1033313903810413e+168\n",
      "The norm of gradient vector is 2.3464084409289477e+88\n",
      "Loss increases to 2.465986596627995e+168\n",
      "The norm of gradient vector is 3.507890118609476e+88\n",
      "Loss increases to 5.511571543930046e+168\n",
      "The norm of gradient vector is 5.244309928993567e+88\n",
      "Loss increases to 1.2318566907621341e+169\n",
      "The norm of gradient vector is 7.840264575403119e+88\n",
      "Loss increases to 2.753245411912771e+169\n",
      "The norm of gradient vector is 1.172122728149244e+89\n",
      "Loss increases to 6.153605654833803e+169\n",
      "The norm of gradient vector is 1.7523282239150544e+89\n",
      "Loss increases to 1.375353696817575e+170\n",
      "The norm of gradient vector is 2.619737789043461e+89\n",
      "Loss increases to 3.073966544905059e+170\n",
      "The norm of gradient vector is 3.9165186006129226e+89\n",
      "Loss increases to 6.870429287433601e+170\n",
      "The norm of gradient vector is 5.855211163918718e+89\n",
      "Loss increases to 1.5355664384787022e+171\n",
      "The norm of gradient vector is 8.753564394846262e+89\n",
      "Loss increases to 3.4320479672136553e+171\n",
      "The norm of gradient vector is 1.3086614209048856e+90\n",
      "Loss increases to 7.6707545529094e+171\n",
      "The norm of gradient vector is 1.9564541223608288e+90\n",
      "Loss increases to 1.7144421049205368e+172\n",
      "The norm of gradient vector is 2.924906833622386e+90\n",
      "Loss increases to 3.831841718895214e+172\n",
      "The norm of gradient vector is 4.3727475577334905e+90\n",
      "Loss increases to 8.564308422270329e+172\n",
      "The norm of gradient vector is 6.537275301854206e+90\n",
      "Loss increases to 1.9141547102555647e+173\n",
      "The norm of gradient vector is 9.773253042392444e+90\n",
      "Loss increases to 4.278206802157953e+173\n",
      "The norm of gradient vector is 1.461105286533386e+91\n",
      "Loss increases to 9.561950945745082e+173\n",
      "The norm of gradient vector is 2.1843583186435253e+91\n",
      "Loss increases to 2.137131516006121e+174\n",
      "The norm of gradient vector is 3.2656245297338085e+91\n",
      "Loss increases to 4.776568236567885e+174\n",
      "The norm of gradient vector is 4.882121892813644e+91\n",
      "Loss increases to 1.0675807243359135e+175\n",
      "The norm of gradient vector is 7.298791994998014e+91\n",
      "Loss increases to 2.386082531488183e+175\n",
      "The norm of gradient vector is 1.0911723581638272e+92\n",
      "Loss increases to 5.332982993501139e+175\n",
      "The norm of gradient vector is 1.631307093059762e+92\n",
      "Loss increases to 1.1919414870882137e+176\n",
      "The norm of gradient vector is 2.4388107084614657e+92\n",
      "Loss increases to 2.6640334506473817e+176\n",
      "The norm of gradient vector is 3.6460318826606253e+92\n",
      "Loss increases to 5.954213611194615e+176\n",
      "The norm of gradient vector is 5.450832425516155e+92\n",
      "Loss increases to 1.3307888352197645e+177\n",
      "The norm of gradient vector is 8.149016543809496e+92\n",
      "Loss increases to 2.9743624256541517e+177\n",
      "The norm of gradient vector is 1.2182812724240496e+93\n",
      "Loss increases to 6.647810385095624e+177\n",
      "The norm of gradient vector is 1.8213354344784824e+93\n",
      "Loss increases to 1.48581028777842e+178\n",
      "The norm of gradient vector is 2.7229038482110678e+93\n",
      "Loss increases to 3.320841124195867e+178\n",
      "The norm of gradient vector is 4.070752276735676e+93\n",
      "Loss increases to 7.422203132433208e+178\n",
      "The norm of gradient vector is 6.085791134136362e+93\n",
      "Loss increases to 1.6588899401937257e+179\n",
      "The norm of gradient vector is 9.09828238382329e+93\n",
      "Loss increases to 3.7076805694669536e+179\n",
      "The norm of gradient vector is 1.3601968998158257e+94\n",
      "Loss increases to 8.286803646297014e+179\n"
     ]
    }
   ],
   "source": [
    "h = LinearRegression()\n",
    "\n",
    "# You may edit the learning rate if the current setting does not yield convergence\n",
    "h.set_learning_rate(0.00000001)\n",
    "\n",
    "# Uncomment the following to fit the vector w to our data. \n",
    "# You may also edit the number of iterations if the current setting does not yield convergence\n",
    "h.fit(X_train, y_train, iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.190278976845773e+177\n",
      "R-squared (R2): -2.98672573874631e+175\n"
     ]
    }
   ],
   "source": [
    "y_pred = h.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R2):\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
